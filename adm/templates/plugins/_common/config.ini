###################################
#####                         #####
#####     GENERAL SECTION     #####
#####                         #####
###################################
# (plugin metadatas)
[general]

# Notes about the name of the plugin:
# - the name of the plugin is given by the content of .layerapi2_label
#   in this directory (format: plugin_{name of the plugin}@mfdata)
# - the old "name" key in this file is not used anymore

# Version of the plugin (X.Y.Z)
# If the value is {% raw %}{{MFMODULE_VERSION}}{% endraw %},
# the current module version is used
version={{cookiecutter.version}}

# Summary (one line) of the goal of the plugin
summary={{cookiecutter.one_line_summary}}

# License of the plugin
license={{cookiecutter.license|default("BSD")}}

# URL of the plugin homepage
url={{cookiecutter.url}}

# Name of the maintainer of the plugin on the form "Firstname FAMILYNAME <email>"
maintainer={{cookiecutter.maintainer}}

# Vendor of the plugin
vendor={{cookiecutter.vendor}}

{% block extra_general %}
{% endblock %}

# Private key to store the file format version
# => THERE IS NO GOOD REASON TO CHANGE THIS VALUE
# So, if you are about to change this value, DON'T DO THIS
__version=1

{% block step %}
#################################
#####                       #####
#####     STEP SECTIONS     #####
#####                       #####
#################################
# (one section [step_xxxxx] for each step)

# You can have several blocks [step_xxxx] if your plugin
# contains several steps.
# If you have only one step in your plugin, please use "main" as your
# step name in [step_xxxxx]. So just one [step_name] section in this case.

[{{main_step|default("step_main", true)}}]
# Command (and args) to be executed
# notes:
# - null means no command to execute
# - this command can be launched several times (see workers/numprocesses)
# - the command must pop redis queue {% raw %}{{MFDATA_CURRENT_STEP_QUEUE}}{% endraw %} (dynamically generated), so it must include {% raw %}{{MFDATA_CURRENT_STEP_QUEUE}}{% endraw %} in its args
# you can use following placeholders:
#     - {% raw %}{{MFDATA_CURRENT_PLUGIN_NAME}}{% endraw %}: replaced by the plugin name
#     - {% raw %}{{MFDATA_CURRENT_STEP_NAME}}{% endraw %}: replaced by the step name
#     - {% raw %}{{MFDATA_CURRENT_PLUGIN_DIR}}{% endraw %}: replaced by the plugin
#         directory fullpath.
#     - {% raw %}{{MFDATA_CURRENT_CONFIG_INI_PATH}}{% endraw %}: replaced by this
#         file fullpath.
#     - {% raw %}{{MFDATA_CURRENT_STEP_QUEUE}}{% endraw %}: replaced by the name of
#         the queue for the plugin/step on redis
#     - {% raw %}{{MFDATA_CURRENT_STEP_DIR}}{% endraw %}: replaced by the step
#         directory
#     - {% raw %}{{ENV_VAR}}{% endraw %}: replaced by the
#         corresponding env var.
# - it's not the command called for each incoming file, it's a daemon
#     implemented with Acquisition framework in Python ; if you want to
#     execute a binary command for each incoming file, please bootstrap
#     a "fork" plugin
cmd_and_args={% raw %}{{MFDATA_CURRENT_PLUGIN_DIR}}{% endraw %}/{{cmd|default("main.py", true)}} --redis-unix-socket-path={% raw %}{{MFMODULE_RUNTIME_HOME}}{% endraw %}/var/redis.socket --config-file={% raw %}{{MFDATA_CURRENT_CONFIG_INI_PATH}}{% endraw %} {% raw %}{{MFDATA_CURRENT_STEP_QUEUE}}{% endraw %}

{% block specific_args %}
{% endblock %}

{% block failure_policy %}
# Failure policy : keep (default), delete or move
arg_failure-policy = {{failurePolicy}}
# Destination directory when failure_policy is move (mandatory in this case)
#arg_failure-policy-move-dest-dir = dest_dir
# Keep tags in an additional file when failure-policy is move (default yes = 1)
#arg_failure-policy-move-keep-tags = 1
# Suffix to add to the filename to keep tags when failure-policy-move-keep-tags
#    is True (default ".tags")
#arg_failure-policy-move-keep-tags-suffix = .tags
{% endblock %}

{% block switch %}
# For data supply with switch plugin : True, False or logical expression
# on file tags
# Example : (x['first.core.original_dirname'] == b'transmet_fac')
switch_logical_condition = {{cookiecutter.switch_logical_condition}}

# If you do not change anything to the incoming file at the filesystem level
# (permissions, user/group, content), you can set this variable to True
# The switch plugin will send to your plugin a hardlink instead of a copy
# (which is better for performances).
# Note: you can add tags because it's not at the filesystem level.
switch_use_hardlink = False
{% endblock %}

{% block app_max_age %}
# If set then the process will be restarted sometime after max_age and
# max_age + random(0, max_age) seconds.
# 0 => disable this feature
max_age = 3600
{% endblock %}

{% block log %}
# Split stdout/stderr logs into different files?
# AUTO => the global conf MFDATA_LOG_TRY_TO_SPLIT_STDOUT_STDERR is used (default: don't split)
# 1    => split
# 0    => don't split
log_split_stdout_stderr=AUTO

# Split logs of multiple workers into different log files?
# AUTO => the global conf MFDATA_LOG_TRY_TO_SPLIT_MULTIPLE_WORKERS is used (default: don't split)
# 1    => split
# 0    => don't split
log_split_multiple_workers=AUTO
{% endblock %}

{% block circus_limits %}
# The number of processes to run for this step
# note: you can use {% raw %}{{MFCOM_HARDWARE_NUMBER_OF_CPU_CORES_MULTIPLIED_BY_2}}{% endraw %}  value
# to avoid a kind of hardware automatic value (see "env |grep HARDWARE" as mfdata
# to find other automatic values)
numprocesses = 1

# The number of seconds to wait for a step to terminate gracefully
# before killing it. When stopping a process, we first send it a TERM signal.
# A step may catch this signal to perform clean up operations before exiting.
# If the worker is still active after {timeout} seconds, we send it a
# KILL signal. It is not possible to catch a KILL signal so the worker will stop.
# If you use the standard Acquisition framework to implement your step, the
# TERM signal is handled like this: "we don't process files anymore but we
# try to end with the current processed file before stopping". So the
# timeout must by greater than the maximum processing time of one file.
# (must be set and >0)
timeout=600

# resource limit for each step process
# rlimit_as => maximum area (in bytes) of address space which may be taken by the process.
# rlimit_nofile => maximum number of open file descriptors for the current process.
# rlimit_stack => maximum size (in bytes) of the call stack for the current process.
#     This only affects the stack of the main thread in a multi-threaded process.
# rlimit_fsize =>  maximum size of a file which the process may create.
# (empty value means no limit)
rlimit_as = 1000000000
rlimit_nofile = 1000
rlimit_stack = 10000000
rlimit_fsize = 10000000000
{% endblock %}

{% endblock %}

{% block extra_daemons %}
# !!! ADVANCED SETTINGS !!!
# You can add extra daemons which will be launched within your plugin
# by providing configuration blocks [extra_daemon_*]
# You have to provide a command to daemonize (the command must run in
# foreground and not daemonize by itself)
# [extra_daemon_foo]
# cmd_and_args = /your/foreground/command command_arg1 command_arg2
# numprocesses=1
# graceful_timeout = 30
# rlimit_as = 1000000000
# rlimit_nofile = 1000
# rlimit_stack = 10000000
# rlimit_fsize = 100000000
# log_split_stdout_stderr=AUTO
# log_split_multiple_workers=AUTO
# max_age=0
{% endblock %}

{% block extra_steps %}
{% endblock %}
